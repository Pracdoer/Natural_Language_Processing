{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "let say right enjoy singl stori set reason set rate 5 star technic issu play disk 5 comput menu program lock lock crash desktop make menu select discov uncheck video hardwar acceler option powerdvd softwar abl enjoy content disk 5 time experi kind problem new disk\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "import nltk\n",
    "from string import punctuation as punc\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wl = WordNetLemmatizer()\n",
    "ps = PorterStemmer()\n",
    "stop_word = list(stop_words.ENGLISH_STOP_WORDS)\n",
    "\n",
    "\n",
    "corpus = open('Movies_TV.txt').read()\n",
    "\n",
    "corpus = re.sub(r'Domain.*\\n', '', corpus)\n",
    "rows = corpus.split('\\n')\n",
    "rows.remove(rows[-1])\n",
    "inputData, y = [], []\n",
    "for row in rows:\n",
    "    _, label, _, review = row.split('\\t')\n",
    "    inputData.append(review)\n",
    "    y.append(label)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(inputData[1])\n",
    "print(\"----------------------\")\n",
    "\n",
    "def normlizing_case(inp):\n",
    "    inp2 = []\n",
    "    for row in inp:\n",
    "        row = row.lower()\n",
    "        inp2.append(row)\n",
    "    return inp2\n",
    "\n",
    "def unwantd_spaces(inp):\n",
    "    inp2 = []\n",
    "    for row in inp:\n",
    "        row = re.sub(' +', ' ', row)\n",
    "        inp2.append(row)\n",
    "    return inp2\n",
    "\n",
    "\n",
    "def r_punc(inp):\n",
    "    inp2 = []\n",
    "    for row in inp:\n",
    "        row = re.sub('[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~]', ' ', row).lower()\n",
    "        inp2.append(row)\n",
    "    return unwantd_spaces(inp2)\n",
    "\n",
    "\n",
    "#### Stop Words #####\n",
    "def r_stop_words(inp):\n",
    "    inp2 = []\n",
    "    for row in inp:\n",
    "        words = word_tokenize(row)\n",
    "        words = [word for word in words if not word in stop_word]\n",
    "        row = ' '.join(words)\n",
    "        inp2.append(row)\n",
    "    return inp2\n",
    "\n",
    "\n",
    "\n",
    "def stemming(inp):\n",
    "    inp2 = []\n",
    "    for row in inp:\n",
    "        words = word_tokenize(row)\n",
    "        words = [ps.stem(word) for word in words if not word in stop_word]\n",
    "        row = ' '.join(words)\n",
    "        inp2.append(row)\n",
    "    return inp2\n",
    "\n",
    "def lemmitization(inp):\n",
    "    inp2 = []\n",
    "    for row in inp:\n",
    "        words = word_tokenize(row)\n",
    "        words = [wl.lemmatize(word) for word in words if not word in stop_word]\n",
    "        row = ' '.join(words)\n",
    "        inp2.append(row)\n",
    "    return inp2\n",
    "\n",
    "def r_num(inp):\n",
    "    inp2 = []\n",
    "    for row in inp:\n",
    "        row = [i for i in row if not re.search(r'\\d', i)]\n",
    "        inp2.append(row)\n",
    "    return inp2\n",
    "\n",
    "inputData = unwantd_spaces(inputData)\n",
    "inputData = normlizing_case(inputData)\n",
    "inputData = r_punc(inputData)\n",
    "inputData = r_stop_words(inputData)\n",
    "inputData = stemming(inputData)\n",
    "inputData = lemmitization(inputData)\n",
    "#inputData[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unigrams [('boy',), ('love',), ('film',), ('youngest',), ('scare',), ('captain',), ('hook',), ('stori',), ('great',), ('think',), ('littl',), ('boy',), ('realli',), ('connect',), ('beauti',), ('fun',), ('music',)]\n",
      "---------\n",
      "bigrams [('boy', 'love'), ('love', 'film'), ('film', 'youngest'), ('youngest', 'scare'), ('scare', 'captain'), ('captain', 'hook'), ('hook', 'stori'), ('stori', 'great'), ('great', 'think'), ('think', 'littl'), ('littl', 'boy'), ('boy', 'realli'), ('realli', 'connect'), ('connect', 'beauti'), ('beauti', 'fun'), ('fun', 'music')]\n",
      "---------\n",
      "trigrams [('boy', 'love', 'film'), ('love', 'film', 'youngest'), ('film', 'youngest', 'scare'), ('youngest', 'scare', 'captain'), ('scare', 'captain', 'hook'), ('captain', 'hook', 'stori'), ('hook', 'stori', 'great'), ('stori', 'great', 'think'), ('great', 'think', 'littl'), ('think', 'littl', 'boy'), ('littl', 'boy', 'realli'), ('boy', 'realli', 'connect'), ('realli', 'connect', 'beauti'), ('connect', 'beauti', 'fun'), ('beauti', 'fun', 'music')]\n"
     ]
    }
   ],
   "source": [
    "from nltk import ngrams\n",
    "#words = words[:100]\n",
    "sentence = inputData[0]\n",
    "words = sentence.split(' ')\n",
    "unigrams = list(ngrams(words, 1))\n",
    "bigrams = list(ngrams(words, 2))\n",
    "trigrams = list(ngrams(words, 3))\n",
    "print(\"unigrams\", unigrams)\n",
    "print(\"---------\")\n",
    "print(\"bigrams\", bigrams)\n",
    "print(\"---------\")\n",
    "print(\"trigrams\", trigrams)\n",
    "\n",
    "# unigrams_prob = [words.count(x)/len(set(words)) for x in words]\n",
    "# print(\"unigram Probs\")\n",
    "# print(unigrams_prob)\n",
    "\n",
    "# print(\"bi grams\")\n",
    "# bigrams_freq = []\n",
    "# for b in bigrams:\n",
    "#     temp = bigrams.count(b)\n",
    "#     temp2 = words.count(b[0])\n",
    "#     bigrams_freq.append(temp/temp2)\n",
    "# bigrams_freq "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.125,\n",
       " 0.0625,\n",
       " 0.0625,\n",
       " 0.0625,\n",
       " 0.0625,\n",
       " 0.0625,\n",
       " 0.0625,\n",
       " 0.0625,\n",
       " 0.0625,\n",
       " 0.0625,\n",
       " 0.0625,\n",
       " 0.125,\n",
       " 0.0625,\n",
       " 0.0625,\n",
       " 0.0625,\n",
       " 0.0625,\n",
       " 0.0625]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigrams_freq = [words.count(x)/len(set(words)) for x in words]\n",
    "unigrams_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.5,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_freq = []\n",
    "for b in bigrams:\n",
    "    temp = bigrams.count(b)\n",
    "    temp2 = words.count(b[0])\n",
    "    bigrams_freq.append(temp/temp2)\n",
    "bigrams_freq "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigrams_freq = [trigrams.count(x)/bigrams.count(x[:2]) for x in trigrams]\n",
    "trigrams_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
